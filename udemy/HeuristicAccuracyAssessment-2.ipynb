{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1571416467653_0002</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-96-102-73-248.ec2.internal:20888/proxy/application_1571416467653_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-96-102-73-223.ec2.internal:8042/node/containerlogs/container_1571416467653_0002_01_000001/livy\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import types as t\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ground_truth():\n",
    "    sources = [\"analyticsEvents\", \"scout\", \"speedTest\", \"xre\"]\n",
    "    days = [19, 20, 21, 22, 23, 24, 25]\n",
    "\n",
    "    ground_truth_raw = None\n",
    "    year = 2019\n",
    "    month = '07'\n",
    "    for day in days:\n",
    "        for source in sources:    \n",
    "            new_df = spark \\\n",
    "                    .read \\\n",
    "                    .parquet(\"s3://reachability-ground-truth/GroundTruthV1.237/\" +\n",
    "                             f\"source={'analyticsEvents'}/\" +\n",
    "                             f\"year={year}/month={month}/day={day}/*.gz.parquet\") \\\n",
    "                    .withColumn(\"source\", F.lit(source)) \\\n",
    "                    .withColumn(\"year\", F.lit(year)) \\\n",
    "                    .withColumn(\"month\", F.lit(month)) \\\n",
    "                    .withColumn(\"day\", F.lit(day))\n",
    "\n",
    "            new_df = new_df.withColumnRenamed(\"mac\", \"gt_mac\")\n",
    "            if ground_truth_raw is None:\n",
    "                ground_truth_raw = new_df\n",
    "            else:\n",
    "                ground_truth_raw = ground_truth_raw \\\n",
    "                    .unionAll(new_df)\n",
    "    \n",
    "            ground_truth_raw.cache()\n",
    "            raw_count = ground_truth_raw.count()\n",
    "            print(\"Ground Truth source: for day: {} raw_count: {}\".format(day, raw_count))    \n",
    "\n",
    "\n",
    "    # Count and Cache ground truth for one day\n",
    "    return ground_truth_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth source: for day: 19 raw_count: 2222761\n",
      "Ground Truth source: for day: 19 raw_count: 4445522\n",
      "Ground Truth source: for day: 19 raw_count: 6668283\n",
      "Ground Truth source: for day: 19 raw_count: 8891044\n",
      "Ground Truth source: for day: 20 raw_count: 10744325\n",
      "Ground Truth source: for day: 20 raw_count: 12597606\n",
      "Ground Truth source: for day: 20 raw_count: 14450887\n",
      "Ground Truth source: for day: 20 raw_count: 16304168\n",
      "Ground Truth source: for day: 21 raw_count: 17964322\n",
      "Ground Truth source: for day: 21 raw_count: 19624476\n",
      "Ground Truth source: for day: 21 raw_count: 21284630\n",
      "Ground Truth source: for day: 21 raw_count: 22944784\n",
      "Ground Truth source: for day: 22 raw_count: 25553906\n",
      "Ground Truth source: for day: 22 raw_count: 28163028\n",
      "Ground Truth source: for day: 22 raw_count: 30772150\n",
      "Ground Truth source: for day: 22 raw_count: 33381272\n",
      "Ground Truth source: for day: 23 raw_count: 35895690\n",
      "Ground Truth source: for day: 23 raw_count: 38410108\n",
      "Ground Truth source: for day: 23 raw_count: 40924526\n",
      "Ground Truth source: for day: 23 raw_count: 43438944\n",
      "Ground Truth source: for day: 24 raw_count: 46073315\n",
      "Ground Truth source: for day: 24 raw_count: 48707686\n",
      "Ground Truth source: for day: 24 raw_count: 51342057\n",
      "Ground Truth source: for day: 24 raw_count: 53976428\n",
      "Ground Truth source: for day: 25 raw_count: 56324786\n",
      "Ground Truth source: for day: 25 raw_count: 58673144\n",
      "Ground Truth source: for day: 25 raw_count: 61021502\n",
      "Ground Truth source: for day: 25 raw_count: 63369860"
     ]
    }
   ],
   "source": [
    "# Very strange that the month partition for Ground Truth contains a leading '0' but preprocessed data doesn't\n",
    "\n",
    "ground_truth = read_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'path s3://via-warren/ground_truth_1_37 already exists.;'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py\", line 841, in parquet\n",
      "    self._jwrite.parquet(path)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 69, in deco\n",
      "    raise AnalysisException(s.split(': ', 1)[1], stackTrace)\n",
      "pyspark.sql.utils.AnalysisException: 'path s3://via-warren/ground_truth_1_37 already exists.;'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ground_truth.write.partitionBy(\"year\",\"month\", \"day\")\\\n",
    "        .parquet(\"s3://via-warren/ground_truth_1_37\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_columns():\n",
    "        # This code gets lists of all of the feature columns in the preprocessed data\n",
    "    delta_columns = []\n",
    "    value_columns = []\n",
    "    lag_inds = [\"lead1\", \"lag0\", \"lag1\", \"lag2\"]\n",
    "    source_prefixes = [\"scout\", \"genome_poller\"]\n",
    "    for prefix in source_prefixes:\n",
    "        for lag_ind in lag_inds:\n",
    "            delta_columns.append(prefix + \"_\" + lag_ind + \"_\" + \"delta\")\n",
    "            value_columns.append(prefix + \"_\" + lag_ind + \"_\" + \"val\")\n",
    "            \n",
    "    return namedtuple('feature_columns', 'values deltas')(value_columns, delta_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scout_lead1_val', 'scout_lag0_val', 'scout_lag1_val', 'scout_lag2_val', 'genome_poller_lead1_val', 'genome_poller_lag0_val', 'genome_poller_lag1_val', 'genome_poller_lag2_val']"
     ]
    }
   ],
   "source": [
    "get_feature_columns().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_preprocessed_data(year, month, day, feature_columns):\n",
    "    # Read in preprocessed data for one day\n",
    "    preprocessed_data = spark.read. \\\n",
    "        parquet(\"s3://rads-prepro-data/\" +\n",
    "                f\"year={year}/month={month}/day={day}/*.gz.parquet\")\n",
    "    \n",
    "    # Count and cache preprocessed data for one day\n",
    "    preprocessed_data.cache()\n",
    "    preprocessed_count = preprocessed_data.count()\n",
    "    print(\"Preprocessed Data count for day \" + str(day) + \": \" + str(preprocessed_count))\n",
    "\n",
    "    # Update delta columns, accounting for 0 delta case (need to do this because of division issues)\n",
    "    for column in feature_columns.deltas:\n",
    "        replacement = None\n",
    "        if \"lag0\" in column:\n",
    "            replacement = 0.0001 # Will weight current values with no delta very highly (these will trump all)\n",
    "        else:\n",
    "            replacement = 9999999999 # Will weight non-current values with no delta very low (essentially throwing out)\n",
    "        preprocessed_data = preprocessed_data. \\\n",
    "            withColumn(column, F.when(F.col(column) == 0, replacement). \\\n",
    "                                 otherwise(F.abs(F.col(column))))\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Data count for day 19: 13149363551\n",
      "13149363551"
     ]
    }
   ],
   "source": [
    "preprocessed_data = read_preprocessed_data(2019, 7, 19, get_feature_columns())\n",
    "preprocessed_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_heuristic_model(preprocessed_data, feature_columns):\n",
    "    # Update value columns, reachable -> 1, unreachable -> -1 (need to do this for heuristic to work)\n",
    "    for column in value_columns:\n",
    "        if \"scout\" in column:\n",
    "            preprocessed_data = preprocessed_data. \\\n",
    "                withColumn(column, F.when(F.col(column) == 6, 1).otherwise(-1))\n",
    "        if \"genome_poller\" in column:\n",
    "            preprocessed_data = preprocessed_data. \\\n",
    "                withColumn(column, F.when(F.col(column) == 1, 1).otherwise(-1))\n",
    "\n",
    "    # Heuristic score computed here. If >= 0 then reachable prediction, otherwise nonreachable prediction\n",
    "    model_scored_data = preprocessed_data. \\\n",
    "        withColumn(\"reachability_score\",\n",
    "                   0.75*(F.col(\"scout_lead1_val\") / F.col(\"scout_lead1_delta\") + \n",
    "                         F.col(\"scout_lag0_val\") / F.col(\"scout_lag0_delta\") +\n",
    "                         F.col(\"scout_lag1_val\") / F.col(\"scout_lag1_delta\") + \n",
    "                         F.col(\"scout_lag2_val\") / F.col(\"scout_lag2_delta\")) + \n",
    "                   0.25*(F.col(\"genome_poller_lead1_val\") / F.col(\"genome_poller_lead1_delta\") + \n",
    "                         F.col(\"genome_poller_lag0_val\") / F.col(\"genome_poller_lag0_delta\") +\n",
    "                         F.col(\"genome_poller_lag1_val\") / F.col(\"genome_poller_lag1_delta\") + \n",
    "                         F.col(\"genome_poller_lag2_val\") / F.col(\"genome_poller_lag2_delta\"))). \\\n",
    "        withColumn(\"heuristic_guess\", F.when(F.col(\"reachability_score\") >= 0, 1).otherwise(-1)). \\\n",
    "        select(\"mac\", \"ts\", \"heuristic_guess\")\n",
    "    \n",
    "    # Count and cache scored preprocessed data for one day\n",
    "    model_scored_data.cache()\n",
    "    model_scored_data = preprocessed_data.count()\n",
    "    print(\"Scored Preprocessed Data count for day \" + str(day) + \": \" + str(preprocessed_count))\n",
    "    \n",
    "    return model_scored_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth source: analyticsEvents for day: 19 raw_count: 2222761\n",
      "Ground Truth source: scout for day: 19 raw_count: 4445522\n",
      "Ground Truth source: speedTest for day: 19 raw_count: 6668283\n",
      "Ground Truth source: xre for day: 19 raw_count: 8891044\n",
      "Ground Truth source: for day: 19 raw_count: 8891044\n",
      "Ground Truth source: analyticsEvents for day: 20 raw_count: 10744325\n",
      "Ground Truth source: scout for day: 20 raw_count: 12597606\n",
      "Ground Truth source: speedTest for day: 20 raw_count: 14450887\n",
      "Ground Truth source: xre for day: 20 raw_count: 16304168\n",
      "Ground Truth source: for day: 20 raw_count: 16304168\n",
      "Ground Truth source: analyticsEvents for day: 21 raw_count: 17964322\n",
      "Ground Truth source: scout for day: 21 raw_count: 19624476\n",
      "Ground Truth source: speedTest for day: 21 raw_count: 21284630\n",
      "Ground Truth source: xre for day: 21 raw_count: 22944784\n",
      "Ground Truth source: for day: 21 raw_count: 22944784\n",
      "Ground Truth source: analyticsEvents for day: 22 raw_count: 25553906\n",
      "Ground Truth source: scout for day: 22 raw_count: 28163028\n",
      "Ground Truth source: speedTest for day: 22 raw_count: 30772150\n",
      "Ground Truth source: xre for day: 22 raw_count: 33381272\n",
      "Ground Truth source: for day: 22 raw_count: 33381272\n",
      "Ground Truth source: analyticsEvents for day: 23 raw_count: 35895690\n",
      "Ground Truth source: scout for day: 23 raw_count: 38410108\n",
      "Ground Truth source: speedTest for day: 23 raw_count: 40924526\n",
      "Ground Truth source: xre for day: 23 raw_count: 43438944\n",
      "Ground Truth source: for day: 23 raw_count: 43438944\n",
      "Ground Truth source: analyticsEvents for day: 24 raw_count: 46073315\n",
      "Ground Truth source: scout for day: 24 raw_count: 48707686\n",
      "Ground Truth source: speedTest for day: 24 raw_count: 51342057\n",
      "Ground Truth source: xre for day: 24 raw_count: 53976428\n",
      "Ground Truth source: for day: 24 raw_count: 53976428\n",
      "Ground Truth source: analyticsEvents for day: 25 raw_count: 56324786\n",
      "Ground Truth source: scout for day: 25 raw_count: 58673144\n",
      "Ground Truth source: speedTest for day: 25 raw_count: 61021502\n",
      "Ground Truth source: xre for day: 25 raw_count: 63369860\n",
      "Ground Truth source: for day: 25 raw_count: 63369860"
     ]
    }
   ],
   "source": [
    "sources = [\"analyticsEvents\", \"scout\", \"speedTest\", \"xre\"]\n",
    "days = [19, 20, 21, 22, 23, 24, 25]\n",
    "\n",
    "ground_truth_raw = None\n",
    "year = 2019\n",
    "month = 7\n",
    "for day in days:\n",
    "    for source in sources:\n",
    "        # Read in raw ground truth from all sources for one day\n",
    "        ground_truth_raw = read_ground_truth(ground_truth_raw, source, year, month, day)\n",
    "    \n",
    "    raw_count = ground_truth_raw.count()\n",
    "    print(\"Ground Truth source: for day: {} raw_count: {}\".format(day, raw_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\"analyticsEvents\", \"scout\", \"speedTest\", \"xre\"]\n",
    "days = [\"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\"]\n",
    "\n",
    "ground_truth_raw = None\n",
    "year = '2019'\n",
    "month = '07'\n",
    "for day in days:\n",
    "    for source in sources:\n",
    "        # Read in raw ground truth from all sources for one day\n",
    "        ground_truth_raw = read_ground_truth(ground_truth_raw, year, month, day)\n",
    "    \n",
    "    raw_count = ground_truth_raw.count()\n",
    "    print(\"Ground Truth source: {} for day: {} count: {}\".format(source, day, raw_count))\n",
    "\n",
    "    # Read in preprocessed data for one day\n",
    "    preprocessed_data = spark.read. \\\n",
    "        parquet(\"s3://rads-prepro-data/\" +\n",
    "                f\"year={year}/month={month}/day={day}/*.gz.parquet\")\n",
    "    \n",
    "    # Count and cache preprocessed data for one day\n",
    "    preprocessed_data.cache()\n",
    "    preprocessed_count = preprocessed_data.count()\n",
    "    print(\"Preprocessed Data count for day \" + str(day) + \": \" + str(preprocessed_count))\n",
    "\n",
    "    # This code gets lists of all of the feature columns in the preprocessed data\n",
    "    delta_columns = []\n",
    "    value_columns = []\n",
    "    lag_inds = [\"lead1\", \"lag0\", \"lag1\", \"lag2\"]\n",
    "    source_prefixes = [\"scout\", \"genome_poller\"]\n",
    "    for prefix in source_prefixes:\n",
    "        for lag_ind in lag_inds:\n",
    "            delta_columns.append(prefix + \"_\" + lag_ind + \"_\" + \"delta\")\n",
    "            value_columns.append(prefix + \"_\" + lag_ind + \"_\" + \"val\")\n",
    "            \n",
    "    # Get heuristic score for preprocessed data\n",
    "    scored_preprocessed_data = preprocessed_data\n",
    "\n",
    "    # Update delta columns, accounting for 0 delta case (need to do this because of division issues)\n",
    "    for column in delta_columns:\n",
    "        replacement = None\n",
    "        if \"lag0\" in column:\n",
    "            replacement = 0.0001 # Will weight current values with no delta very highly (these will trump all)\n",
    "        else:\n",
    "            replacement = 9999999999 # Will weight non-current values with no delta very low (essentially throwing out)\n",
    "        scored_preprocessed_data = scored_preprocessed_data. \\\n",
    "            withColumn(column, F.when(F.col(column) == 0, replacement). \\\n",
    "                                 otherwise(F.abs(F.col(column))))\n",
    "\n",
    "    # Update value columns, reachable -> 1, unreachable -> -1 (need to do this for heuristic to work)\n",
    "    for column in value_columns:\n",
    "        if \"scout\" in column:\n",
    "            scored_preprocessed_data = scored_preprocessed_data. \\\n",
    "                withColumn(column, F.when(F.col(column) == 6, 1).otherwise(-1))\n",
    "        if \"genome_poller\" in column:\n",
    "            scored_preprocessed_data = scored_preprocessed_data. \\\n",
    "                withColumn(column, F.when(F.col(column) == 1, 1).otherwise(-1))\n",
    "\n",
    "    # Heuristic score computed here. If >= 0 then reachable prediction, otherwise nonreachable prediction\n",
    "    scored_preprocessed_data = scored_preprocessed_data. \\\n",
    "        withColumn(\"reachability_score\",\n",
    "                   0.75*(F.col(\"scout_lead1_val\") / F.col(\"scout_lead1_delta\") + \n",
    "                         F.col(\"scout_lag0_val\") / F.col(\"scout_lag0_delta\") +\n",
    "                         F.col(\"scout_lag1_val\") / F.col(\"scout_lag1_delta\") + \n",
    "                         F.col(\"scout_lag2_val\") / F.col(\"scout_lag2_delta\")) + \n",
    "                   0.25*(F.col(\"genome_poller_lead1_val\") / F.col(\"genome_poller_lead1_delta\") + \n",
    "                         F.col(\"genome_poller_lag0_val\") / F.col(\"genome_poller_lag0_delta\") +\n",
    "                         F.col(\"genome_poller_lag1_val\") / F.col(\"genome_poller_lag1_delta\") + \n",
    "                         F.col(\"genome_poller_lag2_val\") / F.col(\"genome_poller_lag2_delta\"))). \\\n",
    "        withColumn(\"heuristic_guess\", F.when(F.col(\"reachability_score\") >= 0, 1).otherwise(-1)). \\\n",
    "        select(\"mac\", \"ts\", \"heuristic_guess\")\n",
    "    \n",
    "    # Count and cache scored preprocessed data for one day\n",
    "    scored_preprocessed_data.cache()\n",
    "    scored_preprocessed_count = scored_preprocessed_data.count()\n",
    "    print(\"Scored Preprocessed Data count for day \" + str(day) + \": \" + str(scored_preprocessed_count))\n",
    "    \n",
    "    # Unpersist original preprocessed data, don't need\n",
    "    preprocessed_data.unpersist()\n",
    "    \n",
    "    # Join Ground Truth to Scored Preprocessed data to assess accuracy\n",
    "    accuracy_join = scored_preprocessed_data \\\n",
    "        .join(ground_truth_raw,\n",
    "              (scored_preprocessed_data.mac == ground_truth_raw.gt_mac) &\n",
    "              (ground_truth_raw.startTs <= scored_preprocessed_data.ts) &\n",
    "              (scored_preprocessed_data.ts <= ground_truth_raw.endTs),\n",
    "              \"left_outer\") \\\n",
    "        .groupBy(\"mac\", \"ts\", \"heuristic_guess\", \"reachable\") \\\n",
    "        .agg(F.collect_set(F.col(\"source\")).alias(\"sources\"))\n",
    "    \n",
    "    # Aggregate Accuracy Metrics into Confusion Matrix Measurements\n",
    "    accuracy_aggregates = accuracy_join \\\n",
    "        .groupBy(\"heuristic_guess\", \"reachable\", \"sources\") \\\n",
    "        .agg(F.count(\"*\").alias(\"entries\"))\n",
    "    \n",
    "    # Count and Cache Accuracy Aggregates so I can see them\n",
    "    accuracy_aggregates.cache()\n",
    "    print(\"Accuracy Aggregates Completed, \" + str(accuracy_aggregates.count()) + \" entries\")\n",
    "    \n",
    "    if acc_agg is None:\n",
    "        acc_agg = accuracy_aggregates\n",
    "    else:\n",
    "        acc_agg = acc_agg.unionAll(accuracy_aggregates)\n",
    "    acc_agg.cache()\n",
    "    \n",
    "    # Write out data to s3\n",
    "    accuracy_aggregates \\\n",
    "        .withColumn(\"sources\", F.regexp_replace(\n",
    "                                   F.regexp_replace(\n",
    "                                       F.col(\"sources\").cast(\"string\"), \"[\", \"\"\n",
    "                                   ), \"]\", \"\"\n",
    "                               )) \\\n",
    "        .withColumn(\"year\", F.lit(\"2019\")) \\\n",
    "        .withColumn(\"month\", F.lit(\"7\")) \\\n",
    "        .withColumn(\"day\", F.lit(day)) \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode(\"append\").format(\"csv\") \\\n",
    "        .save(f\"s3://via-nathan/heuristic_accuracy_assessment/\")\n",
    "    \n",
    "    # unpersist data\n",
    "    scored_preprocessed_data.unpersist()\n",
    "    ground_truth_raw.unpersist()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_raw = None\n",
    "new_df = spark \\\n",
    "        .read \\\n",
    "        .parquet(\"s3://reachability-ground-truth/GroundTruthV1.237/\" +\n",
    "                 f\"source={'analyticsEvents'}/\" +\n",
    "                 f\"year=2019/month=07/day=19/*.gz.parquet\") \\\n",
    "        .withColumn(\"source\", F.lit('analyticsEvents')) \\\n",
    "        .withColumn(\"year\", F.lit(\"2019\")) \\\n",
    "        .withColumn(\"month\", F.lit(\"07\")) \\\n",
    "        .withColumn(\"day\", F.lit('19'))\n",
    "\n",
    "new_df = new_df.withColumnRenamed(\"mac\", \"gt_mac\")\n",
    "if ground_truth_raw is None:\n",
    "    ground_truth_raw = new_df\n",
    "else:\n",
    "    ground_truth_raw = ground_truth_raw \\\n",
    "            .unionAll(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gt_mac: string (nullable = true)\n",
      " |-- startTs: long (nullable = true)\n",
      " |-- endTs: long (nullable = true)\n",
      " |-- reachable: boolean (nullable = true)\n",
      " |-- source: string (nullable = false)\n",
      " |-- year: string (nullable = false)\n",
      " |-- month: string (nullable = false)\n",
      " |-- day: string (nullable = false)"
     ]
    }
   ],
   "source": [
    "ground_truth_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_agg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'acc_agg' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'acc_agg' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_agg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[heuristic_guess: int, reachable: boolean, sources: array<string>, entries: bigint]"
     ]
    }
   ],
   "source": [
    "scored_preprocessed_data.unpersist()\n",
    "ground_truth_raw.unpersist()\n",
    "accuracy_aggregates.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth raw count for day 25: 292738671"
     ]
    }
   ],
   "source": [
    "sources = [\"analyticsEvents\", \"scout\", \"speedTest\", \"xre\"]\n",
    "# days = [\"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\"]\n",
    "day = \"25\"\n",
    "\n",
    "ground_truth_raw = None\n",
    "\n",
    "for source in sources:\n",
    "    # Read in raw ground truth from all sources for one day\n",
    "    new_df = spark \\\n",
    "        .read \\\n",
    "        .parquet(\"s3://reachability-ground-truth/GroundTruthV1.22/\" +\n",
    "                 f\"source={source}/\" +\n",
    "                 f\"year=2019/month=07/day={day}/*.gz.parquet\") \\\n",
    "        .withColumn(\"source\", F.lit(source)) \\\n",
    "        .withColumn(\"year\", F.lit(\"2019\")) \\\n",
    "        .withColumn(\"month\", F.lit(\"07\")) \\\n",
    "        .withColumn(\"day\", F.lit(day))\n",
    "    if ground_truth_raw is None:\n",
    "        ground_truth_raw = new_df\n",
    "    else:\n",
    "        ground_truth_raw = ground_truth_raw \\\n",
    "            .unionAll(new_df)\n",
    "\n",
    "# Count and Cache ground truth for one day\n",
    "ground_truth_raw = ground_truth_raw.withColumnRenamed(\"mac\", \"gt_mac\")\n",
    "ground_truth_raw.cache()\n",
    "raw_count = ground_truth_raw.count()\n",
    "print(\"Ground Truth raw count for day \" + str(day) + \": \" + str(raw_count))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in preprocessed data for one day\n",
    "preprocessed_data = spark.read. \\\n",
    "    parquet(\"s3://rads-prepro-data/\" +\n",
    "            f\"year=2019/month=7/day={day}/*.gz.parquet\")\n",
    "\n",
    "# Count and cache preprocessed data for one day\n",
    "# preprocessed_data.cache()\n",
    "# preprocessed_count = preprocessed_data.count()\n",
    "# print(\"Preprocessed Data count for day \" + str(day) + \": \" + str(preprocessed_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scored Preprocessed Data count for day 25: 13146357906"
     ]
    }
   ],
   "source": [
    "# This code gets lists of all of the feature columns in the preprocessed data\n",
    "delta_columns = []\n",
    "value_columns = []\n",
    "lag_inds = [\"lead1\", \"lag0\", \"lag1\", \"lag2\"]\n",
    "source_prefixes = [\"scout\", \"genome_poller\"]\n",
    "for prefix in source_prefixes:\n",
    "    for lag_ind in lag_inds:\n",
    "        delta_columns.append(prefix + \"_\" + lag_ind + \"_\" + \"delta\")\n",
    "        value_columns.append(prefix + \"_\" + lag_ind + \"_\" + \"val\")\n",
    "\n",
    "# Get heuristic score for preprocessed data\n",
    "scored_preprocessed_data = preprocessed_data\n",
    "\n",
    "# Update delta columns, accounting for 0 delta case (need to do this because of division issues)\n",
    "for column in delta_columns:\n",
    "    replacement = None\n",
    "    if \"lag0\" in column:\n",
    "        replacement = 0.0001 # Will weight current values with no delta very highly (these will trump all)\n",
    "    else:\n",
    "        replacement = 9999999999 # Will weight non-current values with no delta very low (essentially throwing out)\n",
    "    scored_preprocessed_data = scored_preprocessed_data. \\\n",
    "        withColumn(column, F.when(F.col(column) == 0, replacement). \\\n",
    "                             otherwise(F.abs(F.col(column))))\n",
    "\n",
    "# Update value columns, reachable -> 1, unreachable -> -1 (need to do this for heuristic to work)\n",
    "for column in value_columns:\n",
    "    if \"scout\" in column:\n",
    "        scored_preprocessed_data = scored_preprocessed_data. \\\n",
    "            withColumn(column, F.when(F.col(column) == 6, 1).otherwise(-1))\n",
    "    if \"genome_poller\" in column:\n",
    "        scored_preprocessed_data = scored_preprocessed_data. \\\n",
    "            withColumn(column, F.when(F.col(column) == 1, 1).otherwise(-1))\n",
    "\n",
    "# Heuristic score computed here. If >= 0 then reachable prediction, otherwise nonreachable prediction\n",
    "scored_preprocessed_data = scored_preprocessed_data. \\\n",
    "    withColumn(\"reachability_score\",\n",
    "               0.75*(F.col(\"scout_lead1_val\") / F.col(\"scout_lead1_delta\") + \n",
    "                     F.col(\"scout_lag0_val\") / F.col(\"scout_lag0_delta\") +\n",
    "                     F.col(\"scout_lag1_val\") / F.col(\"scout_lag1_delta\") + \n",
    "                     F.col(\"scout_lag2_val\") / F.col(\"scout_lag2_delta\")) + \n",
    "               0.25*(F.col(\"genome_poller_lead1_val\") / F.col(\"genome_poller_lead1_delta\") + \n",
    "                     F.col(\"genome_poller_lag0_val\") / F.col(\"genome_poller_lag0_delta\") +\n",
    "                     F.col(\"genome_poller_lag1_val\") / F.col(\"genome_poller_lag1_delta\") + \n",
    "                     F.col(\"genome_poller_lag2_val\") / F.col(\"genome_poller_lag2_delta\"))). \\\n",
    "    withColumn(\"heuristic_guess\", F.when(F.col(\"reachability_score\") >= 0, 1).otherwise(-1)). \\\n",
    "    select(\"mac\", \"ts\", \"heuristic_guess\")\n",
    "\n",
    "# Count and cache scored preprocessed data for one day\n",
    "scored_preprocessed_data.cache()\n",
    "scored_preprocessed_count = scored_preprocessed_data.count()\n",
    "print(\"Scored Preprocessed Data count for day \" + str(day) + \": \" + str(scored_preprocessed_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpersist original preprocessed data, don't need\n",
    "# preprocessed_data.unpersist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Aggregates Completed, 12 entries"
     ]
    }
   ],
   "source": [
    "# Join Ground Truth to Scored Preprocessed data to assess accuracy\n",
    "accuracy_join = scored_preprocessed_data \\\n",
    "    .join(ground_truth_raw,\n",
    "          (scored_preprocessed_data.mac == ground_truth_raw.gt_mac) &\n",
    "          (ground_truth_raw.startTs <= scored_preprocessed_data.ts) &\n",
    "          (scored_preprocessed_data.ts <= ground_truth_raw.endTs),\n",
    "          \"left_outer\") \\\n",
    "    .groupBy(\"mac\", \"ts\", \"heuristic_guess\", \"reachable\") \\\n",
    "    .agg(F.collect_set(F.col(\"source\")).alias(\"sources\"))\n",
    "\n",
    "# Aggregate Accuracy Metrics into Confusion Matrix Measurements\n",
    "accuracy_aggregates = accuracy_join \\\n",
    "    .groupBy(\"heuristic_guess\", \"reachable\", \"sources\") \\\n",
    "    .agg(F.count(\"*\").alias(\"entries\"))\n",
    "\n",
    "# Count and Cache Accuracy Aggregates so I can see them\n",
    "accuracy_aggregates.cache()\n",
    "print(\"Accuracy Aggregates Completed, \" + str(accuracy_aggregates.count()) + \" entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+-------------------+-----------+\n",
      "|heuristic_guess|reachable|            sources|    entries|\n",
      "+---------------+---------+-------------------+-----------+\n",
      "|             -1|     true|          speedTest|         26|\n",
      "|             -1|     null|                   |   56414423|\n",
      "|              1|     true|          speedTest|      64883|\n",
      "|              1|     null|                   |13035091354|\n",
      "|              1|     true|xre analyticsEvents|      78262|\n",
      "|             -1|     true|xre analyticsEvents|         64|\n",
      "|              1|     true|    analyticsEvents|   12162818|\n",
      "|              1|    false|              scout|       2611|\n",
      "|              1|     true|                xre|    8321245|\n",
      "|             -1|     true|                xre|      82528|\n",
      "|             -1|     true|    analyticsEvents|       5419|\n",
      "|             -1|    false|              scout|   33910703|\n",
      "+---------------+---------+-------------------+-----------+"
     ]
    }
   ],
   "source": [
    "accuracy_aggregates \\\n",
    "    .withColumn(\"sources\", F.regexp_replace(\n",
    "                               F.regexp_replace(\n",
    "                                   F.regexp_replace(\n",
    "                                       F.col(\"sources\").cast(\"string\"), \"\\[\", \"\"\n",
    "                                   ), \"\\]\", \"\"\n",
    "                               ), \"\\,\", \"\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out data to s3\n",
    "accuracy_aggregates \\\n",
    "    .withColumn(\"sources\", F.regexp_replace(\n",
    "                               F.regexp_replace(\n",
    "                                   F.regexp_replace(\n",
    "                                       F.col(\"sources\").cast(\"string\"), \"\\[\", \"\"\n",
    "                                   ), \"\\]\", \"\"\n",
    "                               ), \"\\,\", \"\")) \\\n",
    "    .withColumn(\"year\", F.lit(\"2019\")) \\\n",
    "    .withColumn(\"month\", F.lit(\"7\")) \\\n",
    "    .withColumn(\"day\", F.lit(day)) \\\n",
    "    .coalesce(1) \\\n",
    "    .write \\\n",
    "    .mode(\"append\").format(\"csv\") \\\n",
    "    .save(f\"s3://via-nathan/heuristic_accuracy_assessment/day={day}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+--------------------+-----------+\n",
      "|heuristic_guess|reachable|             sources|    entries|\n",
      "+---------------+---------+--------------------+-----------+\n",
      "|             -1|     true|         [speedTest]|         26|\n",
      "|             -1|     null|                  []|   56414423|\n",
      "|              1|     true|         [speedTest]|      64883|\n",
      "|              1|     null|                  []|13035091354|\n",
      "|              1|     true|[xre, analyticsEv...|      78262|\n",
      "|             -1|     true|[xre, analyticsEv...|         64|\n",
      "|              1|     true|   [analyticsEvents]|   12162818|\n",
      "|              1|    false|             [scout]|       2611|\n",
      "|              1|     true|               [xre]|    8321245|\n",
      "|             -1|     true|               [xre]|      82528|\n",
      "|             -1|     true|   [analyticsEvents]|       5419|\n",
      "|             -1|    false|             [scout]|   33910703|\n",
      "+---------------+---------+--------------------+-----------+"
     ]
    }
   ],
   "source": [
    "accuracy_aggregates.show() # the 25th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+--------------------+-----------+\n",
      "|heuristic_guess|reachable|             sources|    entries|\n",
      "+---------------+---------+--------------------+-----------+\n",
      "|             -1|     true|         [speedTest]|         27|\n",
      "|             -1|     null|                  []|   59321053|\n",
      "|              1|     true|         [speedTest]|      66683|\n",
      "|              1|     null|                  []|13015626171|\n",
      "|              1|     true|[xre, analyticsEv...|      76568|\n",
      "|             -1|     true|[xre, analyticsEv...|         81|\n",
      "|              1|     true|   [analyticsEvents]|   11894990|\n",
      "|              1|    false|             [scout]|       2329|\n",
      "|              1|     true|               [xre]|    8544465|\n",
      "|             -1|     true|               [xre]|      66862|\n",
      "|             -1|     true|   [analyticsEvents]|       4427|\n",
      "|             -1|    false|             [scout]|   41673217|\n",
      "+---------------+---------+--------------------+-----------+"
     ]
    }
   ],
   "source": [
    "accuracy_aggregates.show() # the 24th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+--------------------+-----------+\n",
      "|heuristic_guess|reachable|             sources|    entries|\n",
      "+---------------+---------+--------------------+-----------+\n",
      "|             -1|     true|         [speedTest]|         25|\n",
      "|             -1|     null|                  []|   56685196|\n",
      "|              1|     true|         [speedTest]|      59529|\n",
      "|              1|     null|                  []|12986535890|\n",
      "|              1|     true|[xre, analyticsEv...|      79483|\n",
      "|             -1|     true|[xre, analyticsEv...|         65|\n",
      "|              1|     true|   [analyticsEvents]|   11804385|\n",
      "|              1|    false|             [scout]|       3188|\n",
      "|              1|     true|               [xre]|    8685031|\n",
      "|             -1|     true|               [xre]|      89109|\n",
      "|             -1|     true|   [analyticsEvents]|       5561|\n",
      "|             -1|    false|             [scout]|   74869067|\n",
      "+---------------+---------+--------------------+-----------+"
     ]
    }
   ],
   "source": [
    "accuracy_aggregates.show() # the 23rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+--------------------+-----------+\n",
      "|heuristic_guess|reachable|             sources|    entries|\n",
      "+---------------+---------+--------------------+-----------+\n",
      "|             -1|     true|         [speedTest]|         13|\n",
      "|             -1|     null|                  []|   55494778|\n",
      "|              1|     true|         [speedTest]|      62350|\n",
      "|              1|     null|                  []|12999524260|\n",
      "|              1|     true|[xre, analyticsEv...|      79933|\n",
      "|             -1|     true|[xre, analyticsEv...|         68|\n",
      "|              1|     true|   [analyticsEvents]|   13678165|\n",
      "|              1|    false|             [scout]|       2469|\n",
      "|              1|     true|               [xre]|    8737318|\n",
      "|             -1|     true|               [xre]|      83387|\n",
      "|             -1|     true|   [analyticsEvents]|       4831|\n",
      "|             -1|    false|             [scout]|   45913223|\n",
      "+---------------+---------+--------------------+-----------+"
     ]
    }
   ],
   "source": [
    "accuracy_aggregates.show() # the 22nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+--------------------+-----------+\n",
      "|heuristic_guess|reachable|             sources|    entries|\n",
      "+---------------+---------+--------------------+-----------+\n",
      "|             -1|     true|         [speedTest]|         12|\n",
      "|             -1|     null|                  []|   53589101|\n",
      "|              1|     true|         [speedTest]|      61639|\n",
      "|              1|     null|                  []|12993801419|\n",
      "|              1|     true|[xre, analyticsEv...|      79216|\n",
      "|             -1|     true|[xre, analyticsEv...|         62|\n",
      "|              1|     true|   [analyticsEvents]|   13710594|\n",
      "|              1|    false|             [scout]|       2665|\n",
      "|              1|     true|               [xre]|    9553401|\n",
      "|             -1|     true|               [xre]|      80410|\n",
      "|             -1|     true|   [analyticsEvents]|       4031|\n",
      "|             -1|    false|             [scout]|   68504744|\n",
      "+---------------+---------+--------------------+-----------+"
     ]
    }
   ],
   "source": [
    "accuracy_aggregates.show() # the 21st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+--------------------+-----------+\n",
      "|heuristic_guess|reachable|             sources|    entries|\n",
      "+---------------+---------+--------------------+-----------+\n",
      "|             -1|     true|         [speedTest]|         13|\n",
      "|             -1|     null|                  []|   53756635|\n",
      "|              1|     true|         [speedTest]|      56472|\n",
      "|              1|     null|                  []|13017873036|\n",
      "|              1|     true|[xre, analyticsEv...|      78966|\n",
      "|             -1|     true|[xre, analyticsEv...|         61|\n",
      "|              1|     true|   [analyticsEvents]|   14103325|\n",
      "|              1|    false|             [scout]|       3019|\n",
      "|              1|     true|               [xre]|    9148220|\n",
      "|             -1|     true|               [xre]|      79879|\n",
      "|             -1|     true|   [analyticsEvents]|       3928|\n",
      "|             -1|    false|             [scout]|   55250660|\n",
      "+---------------+---------+--------------------+-----------+"
     ]
    }
   ],
   "source": [
    "accuracy_aggregates.show() # the 20th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+--------------------+--------+\n",
      "|heuristic_guess|reachable|             sources| entries|\n",
      "+---------------+---------+--------------------+--------+\n",
      "|             -1|     null|                  []|  272385|\n",
      "|              1|     true|         [speedTest]|     287|\n",
      "|              1|     null|                  []|65388693|\n",
      "|              1|     true|[xre, analyticsEv...|     453|\n",
      "|              1|     true|   [analyticsEvents]|   73393|\n",
      "|              1|    false|             [scout]|      17|\n",
      "|              1|     true|               [xre]|   42266|\n",
      "|             -1|     true|               [xre]|     371|\n",
      "|             -1|     true|   [analyticsEvents]|      25|\n",
      "|             -1|    false|             [scout]|  177388|\n",
      "+---------------+---------+--------------------+--------+"
     ]
    }
   ],
   "source": [
    "accuracy_aggregates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|sum(CASE WHEN (array_contains(sources, xre) AND array_contains(sources, analyticeEvents)) THEN (entries * 2) ELSE entries END)|\n",
      "+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                                      65955278|\n",
      "+------------------------------------------------------------------------------------------------------------------------------+"
     ]
    }
   ],
   "source": [
    "accuracy_aggregates.agg(F.sum(\n",
    "    F.when(F.array_contains(F.col(\"sources\"), \"xre\") & F.array_contains(F.col(\"sources\"), \"analyticeEvents\"), \n",
    "           F.col(\"entries\")*2).otherwise(F.col(\"entries\")))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_aggregates.agg(F.sum(\"entries\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_preprocessed_data.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_aggregates \\\n",
    "    .withColumn(\"sources\", F.col(\"sources\").cast(\"string\")) \\\n",
    "    .coalesce(1) \\\n",
    "    .write \\\n",
    "    .mode(\"append\").format(\"csv\") \\\n",
    "    .save(\"s3://via-nathan/heuristic_accuracy_assessment/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ground truth dataset using 5 minute windows\n",
    "first_time = floor(datetime(2019, 7, int(day), 0, 0, 0).timestamp())\n",
    "last_time = floor(datetime(2019, 7, int(day), 23, 55, 0).timestamp())\n",
    "time_interval = 60*5\n",
    "\n",
    "all_times_df = spark.range(first_time, last_time + time_interval, time_interval). \\\n",
    "    withColumnRenamed(\"id\", \"ts\")\n",
    "\n",
    "gt_macs = ground_truth_raw.select(F.col(\"mac\").alias(\"mac_\")).distinct()\n",
    "\n",
    "all_mac_times = gt_macs.crossJoin(all_times_df)\n",
    "\n",
    "times_gt_join = all_mac_times \\\n",
    "    .join(ground_truth_raw,\n",
    "          (all_mac_times.mac_ == ground_truth_raw.mac) &\n",
    "          (ground_truth_raw.startTs <= all_mac_times.ts) &\n",
    "          (all_mac_times.ts <= ground_truth_raw.endTs),\n",
    "          \"inner\") \\\n",
    "    .select(\"mac\", \"ts\", \"reachable\", \"source\", \"year\", \"month\", \"day\")\n",
    "\n",
    "five_minute_gt = times_gt_join \\\n",
    "    .groupBy(\"mac\", \"ts\", \"reachable\", \"year\", \"month\", \"day\") \\\n",
    "    .agg(F.collect_set(F.col(\"source\")).alias(\"sources\"))\n",
    "\n",
    "five_minute_gt.cache()\n",
    "five_minute_count = five_minute_gt.count()\n",
    "print(\"5 Minute Ground Truth count for day \" + str(day) + \": \" + str(ground_truth_raw_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_gt_join.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_gt_join.select(\"mac\", \"ts\", \"reachable\", \"year\", \"month\", \"day\"). \\\n",
    "        where(((F.col(\"reachable\") == True) | (F.col(\"reachable\") == False)) &\n",
    "                F.col(\"source\").isin([\"scout\", \"xre\", \"speedTest\", \"analyticsEvents\"])). \\\n",
    "        distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_entries.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gt.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = spark.read. \\\n",
    "    parquet(\"s3://rads-prepro-data/\" +\n",
    "            \"year=2019/month=7/day=19/*.gz.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code gets lists of all of the feature columns in the preprocessed data\n",
    "delta_columns = []\n",
    "value_columns = []\n",
    "lag_inds = [\"lead1\", \"lag0\", \"lag1\", \"lag2\"]\n",
    "source_prefixes = [\"scout\", \"genome_poller\"]\n",
    "for prefix in source_prefixes:\n",
    "    for lag_ind in lag_inds:\n",
    "        delta_columns.append(prefix + \"_\" + lag_ind + \"_\" + \"delta\")\n",
    "        value_columns.append(prefix + \"_\" + lag_ind + \"_\" + \"val\")\n",
    "        \n",
    "for col in delta_columns:\n",
    "    print(col)\n",
    "for col in value_columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get heuristic score for preprocessed data\n",
    "scored_preprocessed_data = preprocessed_data\n",
    "\n",
    "# Update delta columns, accounting for 0 delta case (need to do this because of division issues)\n",
    "for column in delta_columns:\n",
    "    replacement = None\n",
    "    if \"lag0\" in column:\n",
    "        replacement = 0.0001 # Will weight current values with no delta very highly (these will trump all)\n",
    "    else:\n",
    "        replacement = 9999999999 # Will weight non-current values with no delta very low (essentially throwing out)\n",
    "    scored_preprocessed_data = scored_preprocessed_data. \\\n",
    "        withColumn(column, F.when(F.col(column) == 0, replacement). \\\n",
    "                             otherwise(F.abs(F.col(column))))\n",
    "    \n",
    "# Update value columns, reachable -> 1, unreachable -> -1 (need to do this for heuristic to work)\n",
    "for column in value_columns:\n",
    "    if \"scout\" in column:\n",
    "        scored_preprocessed_data = scored_preprocessed_data. \\\n",
    "            withColumn(column, F.when(F.col(column) == 6, 1).otherwise(-1))\n",
    "    if \"genome_poller\" in column:\n",
    "        scored_preprocessed_data = scored_preprocessed_data. \\\n",
    "            withColumn(column, F.when(F.col(column) == 1, 1).otherwise(-1))\n",
    "    \n",
    "# Heuristic score computed here. If >= 0 then reachable prediction, otherwise nonreachable prediction\n",
    "scored_preprocessed_data = scored_preprocessed_data. \\\n",
    "    withColumn(\"reachability_score\",\n",
    "               0.75*(F.col(\"scout_lead1_val\") / F.col(\"scout_lead1_delta\") + \n",
    "                     F.col(\"scout_lag0_val\") / F.col(\"scout_lag0_delta\") +\n",
    "                     F.col(\"scout_lag1_val\") / F.col(\"scout_lag1_delta\") + \n",
    "                     F.col(\"scout_lag2_val\") / F.col(\"scout_lag2_delta\")) + \n",
    "               0.25*(F.col(\"genome_poller_lead1_val\") / F.col(\"genome_poller_lead1_delta\") + \n",
    "                     F.col(\"genome_poller_lag0_val\") / F.col(\"genome_poller_lag0_delta\") +\n",
    "                     F.col(\"genome_poller_lag1_val\") / F.col(\"genome_poller_lag1_delta\") + \n",
    "                     F.col(\"genome_poller_lag2_val\") / F.col(\"genome_poller_lag2_delta\"))). \\\n",
    "    withColumn(\"heuristic_guess\", F.when(F.col(\"reachability_score\") >= 0, 1).otherwise(-1)). \\\n",
    "    select(\"mac\", \"ts\",\n",
    "           \"scout_lead1_val\", \"scout_lag0_val\", \"scout_lag1_val\", \"scout_lag2_val\",\n",
    "           \"scout_lead1_delta\", \"scout_lag0_delta\", \"scout_lag1_delta\", \"scout_lag2_delta\",\n",
    "           \"genome_poller_lead1_val\", \"genome_poller_lag0_val\", \"genome_poller_lag1_val\", \"genome_poller_lag2_val\",\n",
    "           \"genome_poller_lead1_delta\", \"genome_poller_lag0_delta\", \"genome_poller_lag1_delta\", \"genome_poller_lag2_delta\",\n",
    "           \"reachability_score\", \"heuristic_guess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_preprocessed_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_join = scored_preprocessed_data. \\\n",
    "    join(final_gt,\n",
    "         [\"mac\", \"ts\"],\n",
    "         \"left_outer\") #. \\\n",
    "    #groupBy(\"mac\", \"ts\", \"reachable\", \"heuristic_guess\", \"year\", \"month\", \"day\"). \\\n",
    "    #agg(F.collect_set(F.col(\"source\")).alias(\"sources\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_join.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_join.groupBy(\"mac\", \"ts\").agg(F.count(\"*\").alias(\"entries\")).where(F.col(\"entries\") > 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_preprocessed_data.groupBy(\"mac\", \"ts\").agg(F.count(\"*\").alias(\"entries\")).where(F.col(\"entries\") > 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_join.groupBy(\"mac\", \"ts\").agg(F.count(\"*\").alias(\"entries\")).where(F.col(\"entries\") > 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_preprocessed_data.groupBy(\"mac\", \"ts\").agg(F.count(\"*\").alias(\"entries\")).where(F.col(\"entries\") > 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_join.groupBy(\"year\", \"month\", \"day\", \"sources\", \"reachable\", \"heuristic_guess\"). \\\n",
    "    agg(F.count(\"*\").alias(\"entries\")). \\\n",
    "    orderBy(\"year\", \"month\", \"day\", \"sources\", \"reachable\", \"heuristic_guess\"). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_join.groupBy(\"year\", \"month\", \"day\", \"sources\", \"reachable\", \"heuristic_guess\"). \\\n",
    "    agg(F.count(\"*\").alias(\"entries\")). \\\n",
    "    orderBy(\"year\", \"month\", \"day\", \"sources\", \"reachable\", \"heuristic_guess\"). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
